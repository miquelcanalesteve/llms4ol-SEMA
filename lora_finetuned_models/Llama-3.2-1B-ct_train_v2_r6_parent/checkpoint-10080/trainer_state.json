{
  "best_global_step": 6720,
  "best_metric": 0.7034759521484375,
  "best_model_checkpoint": "./lora-output-Llama-3.2-1B-ct_train_v2_r6_parent/checkpoint-6720",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 10080,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02976190476190476,
      "grad_norm": 2.442305326461792,
      "learning_rate": 1.990277777777778e-05,
      "loss": 2.4048,
      "step": 100
    },
    {
      "epoch": 0.05952380952380952,
      "grad_norm": 2.243872880935669,
      "learning_rate": 1.980357142857143e-05,
      "loss": 1.0472,
      "step": 200
    },
    {
      "epoch": 0.08928571428571429,
      "grad_norm": 2.3143248558044434,
      "learning_rate": 1.970436507936508e-05,
      "loss": 0.9499,
      "step": 300
    },
    {
      "epoch": 0.11904761904761904,
      "grad_norm": 1.1577086448669434,
      "learning_rate": 1.960515873015873e-05,
      "loss": 0.8929,
      "step": 400
    },
    {
      "epoch": 0.1488095238095238,
      "grad_norm": 2.436279296875,
      "learning_rate": 1.950595238095238e-05,
      "loss": 0.8488,
      "step": 500
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 2.6253256797790527,
      "learning_rate": 1.9406746031746033e-05,
      "loss": 0.7729,
      "step": 600
    },
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 2.8625736236572266,
      "learning_rate": 1.9307539682539685e-05,
      "loss": 0.7451,
      "step": 700
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 1.3424732685089111,
      "learning_rate": 1.9208333333333337e-05,
      "loss": 0.7211,
      "step": 800
    },
    {
      "epoch": 0.26785714285714285,
      "grad_norm": 2.4528603553771973,
      "learning_rate": 1.9109126984126986e-05,
      "loss": 0.6986,
      "step": 900
    },
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 1.246381163597107,
      "learning_rate": 1.9009920634920634e-05,
      "loss": 0.6915,
      "step": 1000
    },
    {
      "epoch": 0.3273809523809524,
      "grad_norm": 1.7784260511398315,
      "learning_rate": 1.8910714285714286e-05,
      "loss": 0.6802,
      "step": 1100
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 2.0612130165100098,
      "learning_rate": 1.8811507936507938e-05,
      "loss": 0.6809,
      "step": 1200
    },
    {
      "epoch": 0.3869047619047619,
      "grad_norm": 1.4630943536758423,
      "learning_rate": 1.871230158730159e-05,
      "loss": 0.679,
      "step": 1300
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 1.2715193033218384,
      "learning_rate": 1.861309523809524e-05,
      "loss": 0.6691,
      "step": 1400
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 1.5136082172393799,
      "learning_rate": 1.851388888888889e-05,
      "loss": 0.6732,
      "step": 1500
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 2.73410701751709,
      "learning_rate": 1.841468253968254e-05,
      "loss": 0.6634,
      "step": 1600
    },
    {
      "epoch": 0.5059523809523809,
      "grad_norm": 2.348881483078003,
      "learning_rate": 1.831547619047619e-05,
      "loss": 0.6645,
      "step": 1700
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 2.324453830718994,
      "learning_rate": 1.8216269841269842e-05,
      "loss": 0.662,
      "step": 1800
    },
    {
      "epoch": 0.5654761904761905,
      "grad_norm": 2.229094982147217,
      "learning_rate": 1.8117063492063494e-05,
      "loss": 0.6598,
      "step": 1900
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 2.1908011436462402,
      "learning_rate": 1.8017857142857146e-05,
      "loss": 0.6546,
      "step": 2000
    },
    {
      "epoch": 0.625,
      "grad_norm": 2.2668874263763428,
      "learning_rate": 1.7918650793650795e-05,
      "loss": 0.658,
      "step": 2100
    },
    {
      "epoch": 0.6547619047619048,
      "grad_norm": 1.583787441253662,
      "learning_rate": 1.7819444444444447e-05,
      "loss": 0.6561,
      "step": 2200
    },
    {
      "epoch": 0.6845238095238095,
      "grad_norm": 2.8296828269958496,
      "learning_rate": 1.7720238095238095e-05,
      "loss": 0.6566,
      "step": 2300
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 3.3193888664245605,
      "learning_rate": 1.7621031746031747e-05,
      "loss": 0.6535,
      "step": 2400
    },
    {
      "epoch": 0.7440476190476191,
      "grad_norm": 1.12911856174469,
      "learning_rate": 1.75218253968254e-05,
      "loss": 0.6486,
      "step": 2500
    },
    {
      "epoch": 0.7738095238095238,
      "grad_norm": 2.1515815258026123,
      "learning_rate": 1.742261904761905e-05,
      "loss": 0.6511,
      "step": 2600
    },
    {
      "epoch": 0.8035714285714286,
      "grad_norm": 1.6429191827774048,
      "learning_rate": 1.73234126984127e-05,
      "loss": 0.6467,
      "step": 2700
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 1.8327423334121704,
      "learning_rate": 1.722420634920635e-05,
      "loss": 0.6464,
      "step": 2800
    },
    {
      "epoch": 0.8630952380952381,
      "grad_norm": 1.5754826068878174,
      "learning_rate": 1.7125e-05,
      "loss": 0.6463,
      "step": 2900
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 2.6279966831207275,
      "learning_rate": 1.702579365079365e-05,
      "loss": 0.6485,
      "step": 3000
    },
    {
      "epoch": 0.9226190476190477,
      "grad_norm": 1.5376865863800049,
      "learning_rate": 1.6926587301587303e-05,
      "loss": 0.6472,
      "step": 3100
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 2.3960649967193604,
      "learning_rate": 1.6827380952380955e-05,
      "loss": 0.6435,
      "step": 3200
    },
    {
      "epoch": 0.9821428571428571,
      "grad_norm": 1.5390968322753906,
      "learning_rate": 1.6728174603174604e-05,
      "loss": 0.6456,
      "step": 3300
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7060248255729675,
      "eval_runtime": 24.1186,
      "eval_samples_per_second": 34.828,
      "eval_steps_per_second": 4.353,
      "step": 3360
    },
    {
      "epoch": 1.0119047619047619,
      "grad_norm": 1.1938011646270752,
      "learning_rate": 1.6628968253968256e-05,
      "loss": 0.6402,
      "step": 3400
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 2.3586549758911133,
      "learning_rate": 1.6529761904761904e-05,
      "loss": 0.6395,
      "step": 3500
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 2.468968152999878,
      "learning_rate": 1.6430555555555556e-05,
      "loss": 0.6409,
      "step": 3600
    },
    {
      "epoch": 1.1011904761904763,
      "grad_norm": 1.8650341033935547,
      "learning_rate": 1.6331349206349208e-05,
      "loss": 0.6418,
      "step": 3700
    },
    {
      "epoch": 1.130952380952381,
      "grad_norm": 1.7416958808898926,
      "learning_rate": 1.623214285714286e-05,
      "loss": 0.6405,
      "step": 3800
    },
    {
      "epoch": 1.1607142857142858,
      "grad_norm": 1.4053449630737305,
      "learning_rate": 1.6132936507936508e-05,
      "loss": 0.6361,
      "step": 3900
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 1.2940603494644165,
      "learning_rate": 1.603373015873016e-05,
      "loss": 0.6379,
      "step": 4000
    },
    {
      "epoch": 1.2202380952380953,
      "grad_norm": 2.267589569091797,
      "learning_rate": 1.593452380952381e-05,
      "loss": 0.637,
      "step": 4100
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.7250189781188965,
      "learning_rate": 1.583531746031746e-05,
      "loss": 0.6423,
      "step": 4200
    },
    {
      "epoch": 1.2797619047619047,
      "grad_norm": 1.373335599899292,
      "learning_rate": 1.5736111111111112e-05,
      "loss": 0.6371,
      "step": 4300
    },
    {
      "epoch": 1.3095238095238095,
      "grad_norm": 1.6255184412002563,
      "learning_rate": 1.5636904761904764e-05,
      "loss": 0.637,
      "step": 4400
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 1.9748358726501465,
      "learning_rate": 1.5537698412698413e-05,
      "loss": 0.6373,
      "step": 4500
    },
    {
      "epoch": 1.369047619047619,
      "grad_norm": 1.5824322700500488,
      "learning_rate": 1.5438492063492065e-05,
      "loss": 0.6381,
      "step": 4600
    },
    {
      "epoch": 1.3988095238095237,
      "grad_norm": 1.2136207818984985,
      "learning_rate": 1.5339285714285716e-05,
      "loss": 0.6366,
      "step": 4700
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 1.3779442310333252,
      "learning_rate": 1.5240079365079365e-05,
      "loss": 0.6367,
      "step": 4800
    },
    {
      "epoch": 1.4583333333333333,
      "grad_norm": 1.9720957279205322,
      "learning_rate": 1.5140873015873017e-05,
      "loss": 0.6363,
      "step": 4900
    },
    {
      "epoch": 1.4880952380952381,
      "grad_norm": 2.2111449241638184,
      "learning_rate": 1.5041666666666667e-05,
      "loss": 0.6364,
      "step": 5000
    },
    {
      "epoch": 1.5178571428571428,
      "grad_norm": 1.382375955581665,
      "learning_rate": 1.4942460317460319e-05,
      "loss": 0.6352,
      "step": 5100
    },
    {
      "epoch": 1.5476190476190477,
      "grad_norm": 2.5157063007354736,
      "learning_rate": 1.484325396825397e-05,
      "loss": 0.6378,
      "step": 5200
    },
    {
      "epoch": 1.5773809523809523,
      "grad_norm": 2.399101972579956,
      "learning_rate": 1.4744047619047621e-05,
      "loss": 0.6382,
      "step": 5300
    },
    {
      "epoch": 1.6071428571428572,
      "grad_norm": 1.3919891119003296,
      "learning_rate": 1.464484126984127e-05,
      "loss": 0.635,
      "step": 5400
    },
    {
      "epoch": 1.6369047619047619,
      "grad_norm": 1.4373657703399658,
      "learning_rate": 1.4545634920634921e-05,
      "loss": 0.6353,
      "step": 5500
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.734740138053894,
      "learning_rate": 1.4446428571428573e-05,
      "loss": 0.6358,
      "step": 5600
    },
    {
      "epoch": 1.6964285714285714,
      "grad_norm": 1.9703484773635864,
      "learning_rate": 1.4347222222222223e-05,
      "loss": 0.6339,
      "step": 5700
    },
    {
      "epoch": 1.7261904761904763,
      "grad_norm": 1.6949092149734497,
      "learning_rate": 1.4248015873015875e-05,
      "loss": 0.6338,
      "step": 5800
    },
    {
      "epoch": 1.755952380952381,
      "grad_norm": 1.5798817873001099,
      "learning_rate": 1.4148809523809525e-05,
      "loss": 0.6349,
      "step": 5900
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 1.7967132329940796,
      "learning_rate": 1.4049603174603174e-05,
      "loss": 0.6335,
      "step": 6000
    },
    {
      "epoch": 1.8154761904761905,
      "grad_norm": 2.0779428482055664,
      "learning_rate": 1.3951388888888891e-05,
      "loss": 0.634,
      "step": 6100
    },
    {
      "epoch": 1.8452380952380953,
      "grad_norm": 1.935438632965088,
      "learning_rate": 1.3852182539682541e-05,
      "loss": 0.6334,
      "step": 6200
    },
    {
      "epoch": 1.875,
      "grad_norm": 3.8704471588134766,
      "learning_rate": 1.3752976190476193e-05,
      "loss": 0.6334,
      "step": 6300
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 1.5823808908462524,
      "learning_rate": 1.3653769841269842e-05,
      "loss": 0.6339,
      "step": 6400
    },
    {
      "epoch": 1.9345238095238095,
      "grad_norm": 2.3539445400238037,
      "learning_rate": 1.3554563492063494e-05,
      "loss": 0.636,
      "step": 6500
    },
    {
      "epoch": 1.9642857142857144,
      "grad_norm": 1.7703979015350342,
      "learning_rate": 1.3456349206349209e-05,
      "loss": 0.6314,
      "step": 6600
    },
    {
      "epoch": 1.994047619047619,
      "grad_norm": 1.7746728658676147,
      "learning_rate": 1.3357142857142858e-05,
      "loss": 0.6344,
      "step": 6700
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7034759521484375,
      "eval_runtime": 24.0178,
      "eval_samples_per_second": 34.974,
      "eval_steps_per_second": 4.372,
      "step": 6720
    },
    {
      "epoch": 2.0238095238095237,
      "grad_norm": 1.4708056449890137,
      "learning_rate": 1.3257936507936508e-05,
      "loss": 0.631,
      "step": 6800
    },
    {
      "epoch": 2.0535714285714284,
      "grad_norm": 1.8956419229507446,
      "learning_rate": 1.315873015873016e-05,
      "loss": 0.6297,
      "step": 6900
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 1.534446120262146,
      "learning_rate": 1.3059523809523811e-05,
      "loss": 0.6333,
      "step": 7000
    },
    {
      "epoch": 2.113095238095238,
      "grad_norm": 1.5932897329330444,
      "learning_rate": 1.2960317460317462e-05,
      "loss": 0.6303,
      "step": 7100
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 1.4589076042175293,
      "learning_rate": 1.2861111111111114e-05,
      "loss": 0.6311,
      "step": 7200
    },
    {
      "epoch": 2.1726190476190474,
      "grad_norm": 1.3449504375457764,
      "learning_rate": 1.2761904761904762e-05,
      "loss": 0.6285,
      "step": 7300
    },
    {
      "epoch": 2.2023809523809526,
      "grad_norm": 1.4924565553665161,
      "learning_rate": 1.2662698412698414e-05,
      "loss": 0.6307,
      "step": 7400
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 1.5045169591903687,
      "learning_rate": 1.2563492063492064e-05,
      "loss": 0.6287,
      "step": 7500
    },
    {
      "epoch": 2.261904761904762,
      "grad_norm": 1.5911619663238525,
      "learning_rate": 1.2464285714285716e-05,
      "loss": 0.6335,
      "step": 7600
    },
    {
      "epoch": 2.2916666666666665,
      "grad_norm": 1.3788620233535767,
      "learning_rate": 1.2365079365079366e-05,
      "loss": 0.6303,
      "step": 7700
    },
    {
      "epoch": 2.3214285714285716,
      "grad_norm": 1.251003384590149,
      "learning_rate": 1.2265873015873018e-05,
      "loss": 0.6277,
      "step": 7800
    },
    {
      "epoch": 2.3511904761904763,
      "grad_norm": 1.4275307655334473,
      "learning_rate": 1.2166666666666667e-05,
      "loss": 0.6306,
      "step": 7900
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 1.521854043006897,
      "learning_rate": 1.2067460317460318e-05,
      "loss": 0.63,
      "step": 8000
    },
    {
      "epoch": 2.4107142857142856,
      "grad_norm": 1.377046823501587,
      "learning_rate": 1.1968253968253969e-05,
      "loss": 0.629,
      "step": 8100
    },
    {
      "epoch": 2.4404761904761907,
      "grad_norm": 1.6624401807785034,
      "learning_rate": 1.186904761904762e-05,
      "loss": 0.6282,
      "step": 8200
    },
    {
      "epoch": 2.4702380952380953,
      "grad_norm": 1.3999391794204712,
      "learning_rate": 1.176984126984127e-05,
      "loss": 0.6284,
      "step": 8300
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.8034417629241943,
      "learning_rate": 1.1670634920634923e-05,
      "loss": 0.6289,
      "step": 8400
    },
    {
      "epoch": 2.5297619047619047,
      "grad_norm": 1.4019683599472046,
      "learning_rate": 1.1571428571428573e-05,
      "loss": 0.6326,
      "step": 8500
    },
    {
      "epoch": 2.5595238095238093,
      "grad_norm": 2.2801501750946045,
      "learning_rate": 1.1472222222222223e-05,
      "loss": 0.6308,
      "step": 8600
    },
    {
      "epoch": 2.5892857142857144,
      "grad_norm": 2.4902966022491455,
      "learning_rate": 1.1373015873015873e-05,
      "loss": 0.6306,
      "step": 8700
    },
    {
      "epoch": 2.619047619047619,
      "grad_norm": 2.0359983444213867,
      "learning_rate": 1.1273809523809525e-05,
      "loss": 0.6269,
      "step": 8800
    },
    {
      "epoch": 2.6488095238095237,
      "grad_norm": 1.6215665340423584,
      "learning_rate": 1.1174603174603175e-05,
      "loss": 0.6287,
      "step": 8900
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 1.5289103984832764,
      "learning_rate": 1.1075396825396827e-05,
      "loss": 0.628,
      "step": 9000
    },
    {
      "epoch": 2.7083333333333335,
      "grad_norm": 1.9141908884048462,
      "learning_rate": 1.0976190476190479e-05,
      "loss": 0.6325,
      "step": 9100
    },
    {
      "epoch": 2.738095238095238,
      "grad_norm": 1.6765227317810059,
      "learning_rate": 1.0876984126984127e-05,
      "loss": 0.6288,
      "step": 9200
    },
    {
      "epoch": 2.767857142857143,
      "grad_norm": 1.7543549537658691,
      "learning_rate": 1.0777777777777778e-05,
      "loss": 0.6305,
      "step": 9300
    },
    {
      "epoch": 2.7976190476190474,
      "grad_norm": 2.0315513610839844,
      "learning_rate": 1.067857142857143e-05,
      "loss": 0.6306,
      "step": 9400
    },
    {
      "epoch": 2.8273809523809526,
      "grad_norm": 1.5057567358016968,
      "learning_rate": 1.057936507936508e-05,
      "loss": 0.6288,
      "step": 9500
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 2.0305845737457275,
      "learning_rate": 1.0480158730158731e-05,
      "loss": 0.631,
      "step": 9600
    },
    {
      "epoch": 2.886904761904762,
      "grad_norm": 1.1887704133987427,
      "learning_rate": 1.0380952380952383e-05,
      "loss": 0.6288,
      "step": 9700
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 1.2462971210479736,
      "learning_rate": 1.0281746031746032e-05,
      "loss": 0.6288,
      "step": 9800
    },
    {
      "epoch": 2.946428571428571,
      "grad_norm": 1.3153867721557617,
      "learning_rate": 1.0182539682539682e-05,
      "loss": 0.6284,
      "step": 9900
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 1.4260375499725342,
      "learning_rate": 1.0083333333333334e-05,
      "loss": 0.6288,
      "step": 10000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7061209678649902,
      "eval_runtime": 24.1915,
      "eval_samples_per_second": 34.723,
      "eval_steps_per_second": 4.34,
      "step": 10080
    }
  ],
  "logging_steps": 100,
  "max_steps": 20160,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 1,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.030873494519808e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
